{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Die analysis\n",
    "\n",
    "Now we will run a sheet resistance analysis using the device analyses we triggered in the device analysis notebook. Make sure all the analyses from the previous notebook have finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import gfhub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gfhub import nodes\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = gfhub.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Die Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "This function will aggregate device-level resistance measurements to calculate sheet resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def die_sheet_resistance(\n",
    "    files: list[Path],\n",
    "    tags: list[list[str]],\n",
    "    /,\n",
    "    *,\n",
    "    width_key: str = \"width\",\n",
    "    length_key: str = \"length\",\n",
    ") -> tuple[Path, Path, list[str]]:\n",
    "    # Load resistance data\n",
    "    resistances = []\n",
    "    widths = []\n",
    "    lengths = []\n",
    "\n",
    "    for file, file_tags in zip(files, tags):\n",
    "        data = json.loads(file.read_text())\n",
    "\n",
    "        # Extract resistance\n",
    "        resistance = data.get(\"resistance\")\n",
    "        if resistance is None:\n",
    "            continue\n",
    "\n",
    "        # Extract width and length from tags\n",
    "        width = None\n",
    "        length = None\n",
    "        for tag in file_tags:\n",
    "            if tag.startswith(f\"{width_key}:\"):\n",
    "                width = float(tag.split(\":\", 1)[1])\n",
    "            elif tag.startswith(f\"{length_key}:\"):\n",
    "                length = float(tag.split(\":\", 1)[1])\n",
    "\n",
    "        if width is not None and length is not None:\n",
    "            resistances.append(resistance)\n",
    "            widths.append(width)\n",
    "            lengths.append(length)\n",
    "\n",
    "    if len(resistances) == 0:\n",
    "        raise ValueError(\"No valid resistance measurements found\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    resistances = np.array(resistances)\n",
    "    widths = np.array(widths)\n",
    "    lengths = np.array(lengths)\n",
    "\n",
    "    # Calculate R * W / L for each device\n",
    "    # This should be constant and equal to sheet resistance\n",
    "    rw_over_l = resistances * widths / lengths\n",
    "\n",
    "    # Calculate sheet resistance as mean\n",
    "    sheet_resistance = np.mean(rw_over_l)\n",
    "    sheet_resistance_std = np.std(rw_over_l)\n",
    "\n",
    "    # Create plot\n",
    "    # Plot 2: Calculated sheet resistance for each device\n",
    "    plt.scatter(range(len(rw_over_l)), rw_over_l)\n",
    "    plt.axhline(\n",
    "        sheet_resistance,\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mean = {sheet_resistance:.2e}\",\n",
    "    )\n",
    "    plt.axhline(\n",
    "        sheet_resistance + sheet_resistance_std,\n",
    "        color=\"orange\",\n",
    "        linestyle=\":\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.axhline(\n",
    "        sheet_resistance - sheet_resistance_std,\n",
    "        color=\"orange\",\n",
    "        linestyle=\":\",\n",
    "        alpha=0.7,\n",
    "        label=f\"±1σ = {sheet_resistance_std:.2e}\",\n",
    "    )\n",
    "    plt.xlabel(\"Device Index\")\n",
    "    plt.ylabel(\"Sheet Resistance (Ω/sq)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plot_path = files[0].parent / \"die_sheet_resistance.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\", dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    # Extract die coordinates from tags (format: \"die:x,y\")\n",
    "    die_x, die_y = None, None\n",
    "    for tag in tags[0]:\n",
    "        if tag.startswith(\"die:\"):\n",
    "            coords = tag.split(\":\", 1)[1]\n",
    "            die_x, die_y = [int(c) for c in coords.split(\",\")]\n",
    "            break\n",
    "\n",
    "    # Save results\n",
    "    results = {\n",
    "        \"die_x\": die_x,\n",
    "        \"die_y\": die_y,\n",
    "        \"sheet_resistance\": float(sheet_resistance),\n",
    "        \"sheet_resistance_std\": float(sheet_resistance_std),\n",
    "        \"num_devices\": len(resistances),\n",
    "    }\n",
    "\n",
    "    results_path = files[0].parent / \"die_sheet_resistance.json\"\n",
    "    results_path.write_text(json.dumps(results, indent=2))\n",
    "\n",
    "    return plot_path, results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def = gfhub.Function(die_sheet_resistance, dependencies={\n",
    "    \"numpy\": \"import numpy as np\",\n",
    "    \"json\": \"import json\",\n",
    "    \"matplotlib\": \"import matplotlib.pyplot as plt\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = client.query_files(\n",
    "    name=\"*_linear_fit.json\",\n",
    "    tags=[f\"project:resistance\", user]\n",
    ").groupby((\"wafer\", \"die\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (wafer, die) = list(analysis_results)[0]\n",
    "results = analysis_results[key]\n",
    "paths = [client.download_file(r['id'], f\"./download_{i}.json\") for i, r in enumerate(results)]\n",
    "tags = [[gfhub.tags.into_string(t) for t in r[\"tags\"].values()] for r in results]\n",
    "#plot_path, _ = func_def.eval(paths, tags)\n",
    "plot_path, _ = die_sheet_resistance(paths, tags)\n",
    "Image.open(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_function(\n",
    "    name=\"die_sheet_resistance\", \n",
    "    script=func_def,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Tag aggregation\n",
    "\n",
    "To accurately tag the output files, we create a simple function to merge common tags in a list of list of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_tags(\n",
    "    tags: list[list[str]],\n",
    "    /,\n",
    ") -> list[str]:\n",
    "    common = {}\n",
    "    for _tags in tags:\n",
    "        for t in _tags:\n",
    "            if \":\" in t:\n",
    "                key, value = t.split(\":\", 1)\n",
    "            else:\n",
    "                key, value = t, \"\"\n",
    "            if key not in common:\n",
    "                common[key] = set()\n",
    "            common[key].add(value)\n",
    "    common_tags = {k: list(v)[0] for k, v in common.items() if len(v) == 1}\n",
    "    return [k if not v else f\"{k}:{v}\" for k, v in common_tags.items() if not k.startswith('.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Let's prepare a function definition we can upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def = gfhub.Function(find_common_tags, dependencies={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Let's test this on the tags we loaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def.eval(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_function(\"find_common_tags\", func_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "\n",
    "We can now create a pipeline which brings this all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = gfhub.Pipeline()\n",
    "\n",
    "# a pipeline that takes a list of input paths (as opposed to a single input path)\n",
    "# cannot be configure to auto-trigger on upload. Therefore we only add a manual trigger:\n",
    "p.trigger = nodes.on_manual_trigger()\n",
    "\n",
    "# trigger kicks of a load from S3\n",
    "p.load_file = nodes.load()\n",
    "p += p.trigger >> p.load_file\n",
    "\n",
    "# it also kicks of a load of the tags\n",
    "p.load_tags = nodes.load_tags()\n",
    "p += p.trigger >> p.load_tags\n",
    "\n",
    "# the data file path (now on the local filesystem) as well as the\n",
    "# tags get passed to the analysis function\n",
    "p.sheet_resistance = nodes.function(function=\"die_sheet_resistance\")\n",
    "p += p.load_file >> p.sheet_resistance[0]\n",
    "p += p.load_tags >> p.sheet_resistance[1]\n",
    "\n",
    "# we also determine which tags all the data files have in common\n",
    "p.common_tags = nodes.function(function=\"find_common_tags\")\n",
    "p += p.load_tags >> p.common_tags\n",
    "\n",
    "# we save the plot with the common tags\n",
    "p.save_plot = nodes.save()\n",
    "p += p.sheet_resistance[0] >> p.save_plot[0]\n",
    "p += p.common_tags >> p.save_plot[1]\n",
    "\n",
    "# we save the json with the common tags\n",
    "p.save_json = nodes.save()\n",
    "p += p.sheet_resistance[1] >> p.save_json[0]\n",
    "p += p.common_tags >> p.save_json[1]\n",
    "\n",
    "# once the pipeline is defined, we can upload it:\n",
    "confirmation = client.add_pipeline(\"die_sheet_resistance\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Let's upload this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.pipeline_url(confirmation['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Trigger pipeline for all dies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = client.query_files(\n",
    "    name=\"*_linear_fit.json\",\n",
    "    tags=[f\"project:resistance\", user]\n",
    ").groupby((\"wafer\", \"die\"))\n",
    "\n",
    "job_ids = []\n",
    "for die_tag, files in tqdm(analysis_results.items()):\n",
    "    # Get file IDs for this die\n",
    "    input_ids = [f['id'] for f in files]\n",
    "    \n",
    "    # Trigger pipeline\n",
    "    triggered = client.trigger_pipeline(\"die_sheet_resistance\", input_ids)\n",
    "    job_ids.extend(triggered['job_ids'])\n",
    "\n",
    "print(f\"Triggered {len(job_ids)} die analysis jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Wait for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.wait_for_jobs(job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query die analysis plots\n",
    "die_plots = client.query_files(\n",
    "    name=\"die_sheet_resistance.png\",\n",
    "    tags=[f\"project:resistance\", user]\n",
    ")\n",
    "\n",
    "print(f\"Found {len(die_plots)} die analysis plots\")\n",
    "\n",
    "# Display the first plot\n",
    "if die_plots:\n",
    "    img = Image.open(client.download_file(die_plots[0]['id']))\n",
    "    display(img.resize((530, 400)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfhub",
   "language": "python",
   "name": "gfhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Generate measurements\n",
    "\n",
    "For this tutorial you will generate some sample (fake) measurement data so you can post it to your project.\n",
    "\n",
    "You're going to create a new folder and populate it with JSON files containing the fake measurement data for the whole wafer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import gfhub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gfhub import nodes\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(42)  # always generate the same data.\n",
    "user = getpass.getuser()\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = gfhub.Client()\n",
    "device_table_id = client.query_files(name=\"cutback_device_table.csv\").newest().id\n",
    "device_table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_table = pd.read_csv(client.download_file(device_table_id))\n",
    "device_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Grating Coupler Response\n",
    "\n",
    "We can simulate a coupler response as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_grating_coupler_response(peak_power, center_wavelength, bandwidth_1dB, wavelength):\n",
    "    \"\"\"Calculate the response of a Gaussian grating coupler.\n",
    "\n",
    "    Args:\n",
    "        peak_power: The peak power of the response.\n",
    "        center_wavelength: The center wavelength of the grating coupler.\n",
    "        bandwidth_1dB: The 1 dB bandwidth of the coupler.\n",
    "        wavelength: The wavelength at which the response is evaluated.\n",
    "\n",
    "    Returns:\n",
    "     The power of the grating coupler response at the given wavelength.\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert 1 dB bandwidth to standard deviation (sigma)\n",
    "    sigma = bandwidth_1dB / (2 * np.sqrt(2 * np.log(10)))\n",
    "\n",
    "    # Gaussian response calculation\n",
    "    return peak_power * np.exp(-0.5 * ((wavelength - center_wavelength) / sigma) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's have a look at one such responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_power = 1.0\n",
    "center_wavelength = 1.550  # um\n",
    "bandwidth_1dB = 0.100  # um\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"wl [um]\": (\n",
    "            wls := np.linspace(center_wavelength - 0.05, center_wavelength + 0.05, 150)\n",
    "        ),\n",
    "        \"power [dB]\": gaussian_grating_coupler_response(\n",
    "            peak_power, center_wavelength, bandwidth_1dB, wls\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.plot(df['wl [um]'], df['power [dB]'])\n",
    "plt.title(\"Gaussian Grating Coupler Response\")\n",
    "plt.grid(True)\n",
    "plt.xlabel('wl [um]')\n",
    "plt.ylabel('power [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can create a `plot_parquet` function to plot two columns in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parquet(path: Path, /, *, x: str, y: str) -> Path:\n",
    "    df = pd.read_parquet(path)\n",
    "    plt.plot(df[x], df[y])\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    outpath = path.with_suffix(\".png\")\n",
    "    plt.savefig(outpath, bbox_inches=\"tight\")\n",
    "    return outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_def = gfhub.Function(plot_parquet, dependencies={\n",
    "    \"pandas[pyarrow]\": \"import pandas as pd\",\n",
    "    \"matplotlib\": \"import matplotlib.pyplot as plt\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = Path('temp.parquet').resolve()\n",
    "df.to_parquet(temp_path)\n",
    "result = func_def.eval(temp_path, x=\"wl [um]\", y=\"power [dB]\")\n",
    "print(result)\n",
    "Image.open(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_function(\n",
    "    name=\"plot_parquet\", \n",
    "    script=func_def,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Before we actually upload the data, Let's create a pipeline to plot parquet files. This pipeline will essentially generate a .png and link it to the source .parquet file that we're about to upload. By enabling the pipeline, anytime we upload a parquet file in this project it will try to convert it to png:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = gfhub.Pipeline()\n",
    "\n",
    "# auto trigger on file upload for files with the specified tags\n",
    "p.trigger = nodes.on_file_upload(tags=[\".parquet\", \"project:cutback\", user])\n",
    "\n",
    "# load files from S3 to the local file system\n",
    "p.load = nodes.load()\n",
    "\n",
    "# connect the trigger to the load node\n",
    "p += p.trigger >> p.load\n",
    "\n",
    "# once loaded we can plot the file with the function we just created above\n",
    "p.plot = nodes.function(\n",
    "    function=\"plot_parquet\", kwargs={\"x\": \"wl [um]\", \"y\": \"power [dB]\"}\n",
    ")\n",
    "\n",
    "# connect the load node to the plot node\n",
    "p += p.load >> p.plot\n",
    "\n",
    "# once plotted, an output path for the plot on the local file system is created\n",
    "# this one needs to be saved to S3 with a save node:\n",
    "p.save = nodes.save()\n",
    "\n",
    "# connect the plot node to the save node\n",
    "p += p.plot >> p.save[0]\n",
    "\n",
    "# we can also load the tags with which a file was uploaded:\n",
    "p.load_tags = nodes.load_tags()\n",
    "\n",
    "# this tags can also be passed on the the save node's second input\n",
    "# this way the output will have the same tags as the input\n",
    "p += p.trigger >> p.load_tags\n",
    "p += p.load_tags >> p.save[1]\n",
    "\n",
    "# once the pipeline is created locally we can upload it:\n",
    "confirmation = client.add_pipeline(f\"plot_parquet\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The pipeline can be viewed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.pipeline_url(confirmation['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "if anything does not look right you can adjust the pipeline and go to the new url for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "If everything went well, the pipeline is now uploaded and active. Any uploaded `.parquet` file with the `project:cutback` tag will automatically be processed to generate a plot for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Clean up (optional)\n",
    "\n",
    "Let's delete any existing files from this project so you can start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing project files\n",
    "existing_files = client.query_files(tags=[f\"project:cutback\", user])\n",
    "\n",
    "# keep the files uploaded in the previous notebook\n",
    "existing_files = [f for f in existing_files if f['original_name'] not in ('cutback_device_table.csv', 'cutback.gds')]\n",
    "\n",
    "for file in tqdm(existing_files):\n",
    "    client.delete_file(file['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Upload generated spectra\n",
    "\n",
    "You can easily generate some spectrum data and add some noise to make it look like a real measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer_id = \"wafer1\"\n",
    "wafer_definitions = Path(\"wafer_definitions.json\")\n",
    "wafers = [wafer_id]\n",
    "dies = [{\"x\": x, \"y\": y} for y in range(-3, 4) for x in range(-3, 4) if not (abs(y) == 3 and abs(x) == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "grating_coupler_loss_dB = 3\n",
    "device_loss_dB = 0.1\n",
    "noise_peak_to_peak_dB = device_loss_dB / 10\n",
    "device_loss_noise_dB = device_loss_dB / 10 * 2\n",
    "for wafer, die, row in tqdm(\n",
    "    list(itertools.product(wafers, dies, device_table.to_numpy()))\n",
    "):\n",
    "    die = f\"{(die['x'])},{(die['y'])}\"\n",
    "    cell, dev_x, dev_y, components = row\n",
    "    device = f\"{dev_x},{dev_y}\"\n",
    "    T = 25.0  # temperature\n",
    "    loss_dB = 2 * grating_coupler_loss_dB + components * (\n",
    "        device_loss_dB + device_loss_noise_dB * np.random.rand()\n",
    "    )\n",
    "    peak_power = 10 ** (-loss_dB / 10)\n",
    "    output_power = gaussian_grating_coupler_response(\n",
    "        peak_power, center_wavelength, bandwidth_1dB,wls \n",
    "    )\n",
    "    output_power = np.array(output_power)\n",
    "    output_power *= 10 ** (\n",
    "        noise_peak_to_peak_dB * np.random.rand(wls.shape[0]) / 10\n",
    "    )\n",
    "    output_power = 10 * np.log10(output_power)\n",
    "    df = pd.DataFrame({\n",
    "        \"wl [um]\": wls,\n",
    "        \"power [dB]\": output_power,\n",
    "    })\n",
    "    client.add_file(\n",
    "        df,\n",
    "        tags=[\n",
    "            user,\n",
    "            f\"project:cutback\",\n",
    "            f\"wafer:{wafer}\",\n",
    "            f\"die:{die}\",\n",
    "            f\"cell:{cell}\",\n",
    "            f\"device:{device}\",\n",
    "            f\"T:{T}\",\n",
    "            f\"components:{components}\",\n",
    "        ],\n",
    "        filename=\"cutback_device.parquet\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gfhub",
   "language": "python",
   "name": "gfhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
